{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "from environment import GridWorld\n",
    "import cv2\n",
    "\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "from keras import layers\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from keras.models import Model\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "from collections import deque\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "import time\n",
    "from keras.models import load_model\n",
    "from keras.models import clone_model\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pylab\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 10\n",
    "\n",
    "\n",
    "debug_mode = False\n",
    "show_graph_every = 100\n",
    "means = True\n",
    "n_frames = 2\n",
    "manual = False\n",
    "\n",
    "\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('train_dir', 'tf_train_breakout',\n",
    "                           \"\"\"Directory where to write event logs and checkpoint. \"\"\")\n",
    "tf.app.flags.DEFINE_string('restore_file_path',\n",
    "                           'tf_train_breakout/breakout_model_breakout_scratch',\n",
    "                           #'tf_train_breakout/breakout_model_testGridWordl1',\n",
    "                           \"\"\"Path of the restore file \"\"\")\n",
    "tf.app.flags.DEFINE_integer('num_episode', 100000,\n",
    "                            \"\"\"number of epochs of the optimization loop.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('observe_step_num', 1,\n",
    "                            \"\"\"Timesteps to observe before training.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('epsilon_step_num', 1000000,\n",
    "                            \"\"\"frames over which to anneal epsilon.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('refresh_target_model_num', 10000,  # update the target Q model every refresh_target_model_num\n",
    "                            \"\"\"frames over which to anneal epsilon.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('replay_memory', 100000,  # takes up to 20 GB to store this amount of history data\n",
    "                            \"\"\"number of previous transitions to remember.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('no_op_steps', 1,\n",
    "                            \"\"\"Number of the steps that runs before script begin.\"\"\")\n",
    "tf.app.flags.DEFINE_float('regularizer_scale', 0.01,\n",
    "                          \"\"\"L1 regularizer scale.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('batch_size', 64,\n",
    "                            \"\"\"Size of minibatch to train.\"\"\")\n",
    "tf.app.flags.DEFINE_float('learning_rate', 0.0025,\n",
    "                          \"\"\"Number of batches to run.\"\"\")\n",
    "tf.app.flags.DEFINE_float('init_epsilon', 1.0,\n",
    "                          \"\"\"starting value of epsilon.\"\"\")\n",
    "tf.app.flags.DEFINE_float('final_epsilon', 0.1,\n",
    "                          \"\"\"final value of epsilon.\"\"\")\n",
    "tf.app.flags.DEFINE_float('gamma', 0.01,\n",
    "                          \"\"\"decay rate of past observations.\"\"\")\n",
    "tf.app.flags.DEFINE_boolean('resume', False,\n",
    "                            \"\"\"Whether to resume from previous checkpoint.\"\"\")\n",
    "tf.app.flags.DEFINE_boolean('render', False,\n",
    "                            \"\"\"Whether to display the game.\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if manual:\n",
    "    cv2.namedWindow('GUI')\n",
    "\n",
    "ATARI_SHAPE = (5, 8, n_frames)  # input image size to model\n",
    "ACTION_SIZE = 5\n",
    "\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "now = 'testGridWordl2'\n",
    "\n",
    "scores = []\n",
    "averages = []\n",
    "episodes = []\n",
    "\n",
    "# 210*160*3(color) --> 84*84(mono)\n",
    "# float --> integer (to reduce the size of replay memory)\n",
    "def pre_processing(observe):\n",
    "    return observe\n",
    "\n",
    "\n",
    "def huber_loss(y, q_value):\n",
    "    error = K.abs(y - q_value)\n",
    "    quadratic_part = K.clip(error, 0.0, 1.0)\n",
    "    linear_part = error - quadratic_part\n",
    "    loss = K.mean(0.5 * K.square(quadratic_part) + linear_part)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def atari_model():\n",
    "    # With the functional API we need to define the inputs.\n",
    "    frames_input = layers.Input(ATARI_SHAPE, name='frames')\n",
    "    actions_input = layers.Input((ACTION_SIZE,), name='action_mask')\n",
    "    '''\n",
    "    # Assuming that the input frames are still encoded from 0 to 255. Transforming to [0, 1].\n",
    "    #normalized = layers.Lambda(lambda x: x / 2, name='normalization')(frames_input)\n",
    "    \n",
    "    # \"The first hidden layer convolves 16 8×8 filters with stride 4 with the input image and applies a rectifier nonlinearity.\"\n",
    "    conv_1 = layers.convolutional.Conv2D(\n",
    "        32, (2, 2), strides=(1, 1), activation='relu'\n",
    "    )(frames_input)\n",
    "\n",
    "    # \"The second hidden layer convolves 32 4×4 filters with stride 2, again followed by a rectifier nonlinearity.\"\n",
    "    conv_2 = layers.convolutional.Conv2D(\n",
    "        32, (2, 2), strides=(2, 2), activation='relu'\n",
    "    )(conv_1)\n",
    "    '''\n",
    "    \n",
    "    # Flattening the second convolutional layer.\n",
    "    conv_flattened = layers.core.Flatten()(frames_input)\n",
    "    # \"The final hidden layer is fully-connected and consists of 256 rectifier units.\"\n",
    "    hidden = layers.Dense(256, activation='relu')(conv_flattened)\n",
    "    # \"The output layer is a fully-connected linear layer with a single output for each valid action.\"\n",
    "    output = layers.Dense(ACTION_SIZE)(hidden)\n",
    "    # Finally, we multiply the output by the mask!\n",
    "    filtered_output = layers.Multiply(name='QValue')([output, actions_input])\n",
    "\n",
    "    model = Model(inputs=[frames_input, actions_input], outputs=filtered_output)\n",
    "    model.summary()\n",
    "    optimizer = RMSprop(lr=FLAGS.learning_rate, rho=0.95, epsilon=0.01)\n",
    "    # model.compile(optimizer, loss='mse')\n",
    "    # to changed model weights more slowly, uses MSE for low values and MAE(Mean Absolute Error) for large values\n",
    "    model.compile(optimizer, loss=huber_loss)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# get action from model using epsilon-greedy policy\n",
    "def get_action(history, epsilon, step, model):\n",
    "    '''\n",
    "    print(history.shape)\n",
    "    print('-------------------------------------------------------------')\n",
    "    objecto = np.reshape(history[0,:,:,0], (5, 8))\n",
    "    print(objecto)\n",
    "    objecto = np.reshape(history[0,:,:,1], (5, 8))\n",
    "    print(objecto)\n",
    "    '''\n",
    "    \n",
    "    if np.random.rand() <= epsilon or step <= FLAGS.observe_step_num:\n",
    "        if manual:\n",
    "            key = cv2.waitKey(0)\n",
    "            if key == ord('w'):\n",
    "                return 4\n",
    "            elif key == ord('s'):\n",
    "                return 3\n",
    "            elif key == ord('a'):\n",
    "                return 2\n",
    "            elif key == ord('d'):\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        else:\n",
    "            return random.randrange(ACTION_SIZE)\n",
    "    else:\n",
    "        q_value = model.predict([history, np.ones(ACTION_SIZE).reshape(1, ACTION_SIZE)])\n",
    "        return np.argmax(q_value[0])\n",
    "\n",
    "\n",
    "# save sample <s,a,r,s'> to the replay memory\n",
    "def store_memory(memory, history, action, reward, next_history):\n",
    "    memory.append((history, action, reward, next_history))\n",
    "\n",
    "\n",
    "def get_one_hot(targets, nb_classes):\n",
    "    return np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
    "\n",
    "\n",
    "# train model by random batch\n",
    "def train_memory_batch(memory, model, log_dir):\n",
    "    mini_batch = random.sample(memory, FLAGS.batch_size)\n",
    "    history = np.zeros((FLAGS.batch_size, ATARI_SHAPE[0],\n",
    "                        ATARI_SHAPE[1], ATARI_SHAPE[2]))\n",
    "    next_history = np.zeros((FLAGS.batch_size, ATARI_SHAPE[0],\n",
    "                             ATARI_SHAPE[1], ATARI_SHAPE[2]))\n",
    "    target = np.zeros((FLAGS.batch_size,))\n",
    "    action, reward = [], []\n",
    "\n",
    "    for idx, val in enumerate(mini_batch):\n",
    "        history[idx] = val[0]\n",
    "        next_history[idx] = val[3]\n",
    "        action.append(val[1])\n",
    "        reward.append(val[2])\n",
    "\n",
    "    actions_mask = np.ones((FLAGS.batch_size, ACTION_SIZE))\n",
    "    next_Q_values = model.predict([next_history, actions_mask])\n",
    "    print(next_Q_values)\n",
    "\n",
    "    # like Q Learning, get maximum Q value at s'\n",
    "    # But from target model\n",
    "    for i in range(FLAGS.batch_size):\n",
    "        target[i] = reward[i] + FLAGS.gamma * np.amax(next_Q_values[i])\n",
    "\n",
    "    action_one_hot = get_one_hot(action, ACTION_SIZE)\n",
    "    target_one_hot = action_one_hot * target[:, None]\n",
    "\n",
    "    #tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=0,\n",
    "    #                          write_graph=True, write_images=False)\n",
    "\n",
    "    ''''''\n",
    "    h = model.fit(\n",
    "        [history, action_one_hot], target_one_hot, epochs=1,\n",
    "        batch_size=FLAGS.batch_size, verbose=0)\n",
    "        #batch_size=FLAGS.batch_size, verbose=0, callbacks=[tb_callback])\n",
    "\n",
    "    #if h.history['loss'][0] > 10.0:\n",
    "    #    print('too large')\n",
    "\n",
    "    return h.history['loss'][0]\n",
    "\n",
    "def train():\n",
    "    \n",
    "    \n",
    "    env = GridWorld(show_graph_every, debug_mode, means)\n",
    "    \n",
    "    \n",
    "    # deque: Once a bounded length deque is full, when new items are added,\n",
    "    # a corresponding number of items are discarded from the opposite end\n",
    "    memory = deque(maxlen=FLAGS.replay_memory)\n",
    "    episode_number = 0\n",
    "    epsilon = FLAGS.init_epsilon\n",
    "    epsilon_decay = (FLAGS.init_epsilon - FLAGS.final_epsilon) / FLAGS.epsilon_step_num\n",
    "    global_step = 0\n",
    "\n",
    "    \n",
    "    if FLAGS.resume:\n",
    "        \n",
    "        # load json and create model\n",
    "        json_file = open(FLAGS.restore_file_path+'.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        model = model_from_json(loaded_model_json)\n",
    "        # load weights into new model\n",
    "        model.load_weights(FLAGS.restore_file_path+'.h5')\n",
    "        \n",
    "        optimizer = RMSprop(lr=FLAGS.learning_rate, rho=0.95, epsilon=0.01)\n",
    "        # model.compile(optimizer, loss='mse')\n",
    "        # to changed model weights more slowly, uses MSE for low values and MAE(Mean Absolute Error) for large values\n",
    "        model.compile(optimizer, loss=huber_loss)\n",
    "        \n",
    "        print(\"Loaded model from disk\")\n",
    "        '''\n",
    "        model = load_model('tf_train_breakout/breakout_model_20180610205843_36h_12193ep_sec_version_back.h5')#, custom_objects={'huber_loss': huber_loss})\n",
    "        print(\"Loaded model from disk\")\n",
    "        #model = load_model(FLAGS.restore_file_path)\n",
    "        '''\n",
    "        #model = load_model(FLAGS.restore_file_path)\n",
    "        # Assume when we restore the model, the epsilon has already decreased to the final value\n",
    "        epsilon = FLAGS.final_epsilon\n",
    "    else:\n",
    "        model = atari_model()\n",
    "\n",
    "    log_dir = \"logs/{}/run-{}-log\".format(FLAGS.train_dir, now)\n",
    "    file_writer = tf.summary.FileWriter(log_dir, tf.get_default_graph())\n",
    "\n",
    "    model_target = clone_model(model)\n",
    "    model_target.set_weights(model.get_weights())\n",
    "\n",
    "    while episode_number < FLAGS.num_episode:\n",
    "\n",
    "        done = False\n",
    "        # 1 episode = 5 lives\n",
    "        step, score = 0, 0\n",
    "        loss = 0.0\n",
    "        observe = env.reset() \n",
    "        '''\n",
    "        # this is one of DeepMind's idea.\n",
    "        # just do nothing at the start of episode to avoid sub-optimal\n",
    "        for _ in range(random.randint(1, FLAGS.no_op_steps)):\n",
    "            observe, _, _, _, _ = env.step(1)\n",
    "        '''\n",
    "        # At start of episode, there is no preceding frame\n",
    "        # So just copy initial states to make history\n",
    "        state = pre_processing(observe)\n",
    "        history = np.stack((state, state), axis=2)\n",
    "        history = np.reshape([history], (1, 5, 8, n_frames))\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            # get action for the current history and go one step in environment\n",
    "            action = get_action(history, epsilon, global_step, model_target)\n",
    "            # change action to real_action\n",
    "            real_action = action #+ 1\n",
    "\n",
    "            # scale down epsilon, the epsilon only begin to decrease after observe steps\n",
    "            if epsilon > FLAGS.final_epsilon and global_step > FLAGS.observe_step_num:\n",
    "                epsilon -= epsilon_decay\n",
    "\n",
    "            #observe, reward, done, info = env.step(real_action)\n",
    "            observe_past, reward, total_reward, observe, done = env.step(real_action)\n",
    "            # pre-process the observation --> history\n",
    "            next_state = pre_processing(observe)\n",
    "            next_state = np.reshape([next_state], (1, 5, 8, 1))\n",
    "            next_history = np.append(next_state, history[:, :, :, :n_frames-1], axis=3)\n",
    "            \n",
    "            # save the statue to memory, each replay takes 2 * (84*84*4) bytes = 56448 B = 55.125 KB\n",
    "            store_memory(memory, history, action, reward, next_history)  #\n",
    "\n",
    "            # check if the memory is ready for training\n",
    "            if global_step > FLAGS.observe_step_num:\n",
    "                loss = loss + train_memory_batch(memory, model, log_dir)\n",
    "                # if loss > 100.0:\n",
    "                #    print(loss)\n",
    "                if global_step % FLAGS.refresh_target_model_num == 0:  # update the target model\n",
    "                    model_target.set_weights(model.get_weights())\n",
    "\n",
    "            score += reward\n",
    "            history = next_history\n",
    "\n",
    "            #print(\"step: \", global_step)\n",
    "            global_step += 1\n",
    "            step += 1\n",
    "\n",
    "            if done:\n",
    "                if global_step <= FLAGS.observe_step_num:\n",
    "                    state = \"observe\"\n",
    "                elif FLAGS.observe_step_num < global_step <= FLAGS.observe_step_num + FLAGS.epsilon_step_num:\n",
    "                    state = \"explore\"\n",
    "                else:\n",
    "                    state = \"train\"\n",
    "                print('state: {}, episode: {}, score: {}, global_step: {}, avg loss: {}, step: {}, memory length: {}'\n",
    "                      .format(state, episode_number, score, global_step, loss / float(step), step, len(memory)))\n",
    "\n",
    "                if episode_number % 100 == 0 or (episode_number + 1) == FLAGS.num_episode:\n",
    "        \n",
    "                #if episode_number % 1 == 0 or (episode_number + 1) == FLAGS.num_episode:  # debug\n",
    "                    file_name = \"breakout_model_{}\".format(now)\n",
    "                    model_path = os.path.join(FLAGS.train_dir, file_name)\n",
    "                    \n",
    "                    # serialize model to JSON\n",
    "                    model_json = model.to_json()\n",
    "                    with open(model_path+'.json', \"w\") as json_file:\n",
    "                        json_file.write(model_json)\n",
    "                    # serialize weights to HDF5\n",
    "                    model.save_weights(model_path+'.h5')\n",
    "                    #model.save(model_path)\n",
    "\n",
    "                # Add user custom data to TensorBoard\n",
    "                loss_summary = tf.Summary(\n",
    "                    value=[tf.Summary.Value(tag=\"loss\", simple_value=loss / float(step))])\n",
    "                file_writer.add_summary(loss_summary, global_step=episode_number)\n",
    "\n",
    "                score_summary = tf.Summary(\n",
    "                    value=[tf.Summary.Value(tag=\"score\", simple_value=score)])\n",
    "                file_writer.add_summary(score_summary, global_step=episode_number)\n",
    "\n",
    "                episode_number += 1\n",
    "                PlotModel(score, episode_number)\n",
    "\n",
    "    file_writer.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def PlotModel(score, episode_number):\n",
    "    scores.append(score)\n",
    "    averages.append(sum(scores[-50:]) / len(scores[-50:]))\n",
    "    episodes.append(episode_number)\n",
    "    pylab.plot(episodes, scores, 'b')\n",
    "    pylab.plot(episodes, averages, 'r')\n",
    "    pylab.ylabel('Score', fontsize=18)\n",
    "    pylab.xlabel('Games', fontsize=18)\n",
    "    file_name = \"breakout_model_{}\".format(now)\n",
    "    name = file_name + '.png'\n",
    "    try:\n",
    "        if not os.path.exists('training_images'): os.makedirs('training_images')\n",
    "        pylab.savefig('training_images/'+name)\n",
    "\n",
    "    except OSError as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    return             \n",
    "                \n",
    "     \n",
    "                \n",
    "                \n",
    "                \n",
    "def main(argv=None):\n",
    "    train()\n",
    "    #test()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "from scores.score_logger import ScoreLogger\n",
    "\n",
    "ENV_NAME = \"CartPole-v1\"\n",
    "\n",
    "GAMMA = 0.95\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "MEMORY_SIZE = 1000000\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "EXPLORATION_MAX = 1.0\n",
    "EXPLORATION_MIN = 0.01\n",
    "EXPLORATION_DECAY = 0.995\n",
    "\n",
    "\n",
    "class DQNSolver:\n",
    "\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        self.exploration_rate = EXPLORATION_MAX\n",
    "\n",
    "        self.action_space = action_space\n",
    "        self.memory = deque(maxlen=MEMORY_SIZE)\n",
    "\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(24, input_shape=(observation_space,), activation=\"relu\"))\n",
    "        self.model.add(Dense(24, activation=\"relu\"))\n",
    "        self.model.add(Dense(self.action_space, activation=\"linear\"))\n",
    "        self.model.compile(loss=\"mse\", optimizer=Adam(lr=LEARNING_RATE))\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() < self.exploration_rate:\n",
    "            return random.randrange(self.action_space)\n",
    "        q_values = self.model.predict(state)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "    def experience_replay(self):\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "        batch = random.sample(self.memory, BATCH_SIZE)\n",
    "        for state, action, reward, state_next, terminal in batch:\n",
    "            q_update = reward\n",
    "            if not terminal:\n",
    "                q_update = (reward + GAMMA * np.amax(self.model.predict(state_next)[0]))\n",
    "            q_values = self.model.predict(state)\n",
    "            q_values[0][action] = q_update\n",
    "            self.model.fit(state, q_values, verbose=0)\n",
    "        self.exploration_rate *= EXPLORATION_DECAY\n",
    "        self.exploration_rate = max(EXPLORATION_MIN, self.exploration_rate)\n",
    "\n",
    "\n",
    "def cartpole():\n",
    "    env = gym.make(ENV_NAME)\n",
    "    score_logger = ScoreLogger(ENV_NAME)\n",
    "    observation_space = env.observation_space.shape[0]\n",
    "    action_space = env.action_space.n\n",
    "    dqn_solver = DQNSolver(observation_space, action_space)\n",
    "    run = 0\n",
    "    while True:\n",
    "        run += 1\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, observation_space])\n",
    "        step = 0\n",
    "        while True:\n",
    "            step += 1\n",
    "            #env.render()\n",
    "            action = dqn_solver.act(state)\n",
    "            state_next, reward, terminal, info = env.step(action)\n",
    "            reward = reward if not terminal else -reward\n",
    "            state_next = np.reshape(state_next, [1, observation_space])\n",
    "            dqn_solver.remember(state, action, reward, state_next, terminal)\n",
    "            state = state_next\n",
    "            if terminal:\n",
    "                print \"Run: \" + str(run) + \", exploration: \" + str(dqn_solver.exploration_rate) + \", score: \" + str(step)\n",
    "                score_logger.add_score(step, run)\n",
    "                break\n",
    "            dqn_solver.experience_replay()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cartpole()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lorenzo/anaconda3/envs/lorenzo_env/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Model loaded\n",
      "Run: 1, exploration: 0.01, score: 38.1 step: 9\n",
      "Run: 2, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 3, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 4, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 5, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 6, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 7, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 8, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 9, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 10, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 11, exploration: 0.01, score: 43.2 step: 30\n",
      "Run: 12, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 13, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 14, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 15, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 16, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 17, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 18, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 19, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 20, exploration: 0.01, score: 42.5 step: 20\n",
      "model saved\n",
      "Run: 21, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 22, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 23, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 24, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 25, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 26, exploration: 0.01, score: 46.7 step: 32\n",
      "Run: 27, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 28, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 29, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 30, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 31, exploration: 0.01, score: -7.5 step: 50\n",
      "Run: 32, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 33, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 34, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 35, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 36, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 37, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 38, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 39, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 40, exploration: 0.01, score: 47.1 step: 33\n",
      "model saved\n",
      "Run: 41, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 42, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 43, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 44, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 45, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 46, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 47, exploration: 0.01, score: 39.8 step: 3\n",
      "Run: 48, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 49, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 50, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 51, exploration: 0.01, score: 40.4 step: 22\n",
      "Run: 52, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 53, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 54, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 55, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 56, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 57, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 58, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 59, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 60, exploration: 0.01, score: 42.5 step: 23\n",
      "model saved\n",
      "Run: 61, exploration: 0.01, score: 45.9 step: 30\n",
      "Run: 62, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 63, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 64, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 65, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 66, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 67, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 68, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 69, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 70, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 71, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 72, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 73, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 74, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 75, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 76, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 77, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 78, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 79, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 80, exploration: 0.01, score: 40.8 step: 13\n",
      "model saved\n",
      "Run: 81, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 82, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 83, exploration: 0.01, score: 39.8 step: 3\n",
      "Run: 84, exploration: 0.01, score: 39.2 step: 15\n",
      "Run: 85, exploration: 0.01, score: 38.8 step: 16\n",
      "Run: 86, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 87, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 88, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 89, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 90, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 91, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 92, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 93, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 94, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 95, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 96, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 97, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 98, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 99, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 100, exploration: 0.01, score: 43.8 step: 24\n",
      "model saved\n",
      "Run: 101, exploration: 0.01, score: 40.3 step: 31\n",
      "Run: 102, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 103, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 104, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 105, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 106, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 107, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 108, exploration: 0.01, score: 46.3 step: 31\n",
      "Run: 109, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 110, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 111, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 112, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 113, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 114, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 115, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 116, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 117, exploration: 0.01, score: 41.6 step: 20\n",
      "Run: 118, exploration: 0.01, score: 41.8 step: 24\n",
      "Run: 119, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 120, exploration: 0.01, score: 42.5 step: 20\n",
      "model saved\n",
      "Run: 121, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 122, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 123, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 124, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 125, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 126, exploration: 0.01, score: 37.3 step: 35\n",
      "Run: 127, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 128, exploration: 0.01, score: 39.8 step: 3\n",
      "Run: 129, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 130, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 131, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 132, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 133, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 134, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 135, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 136, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 137, exploration: 0.01, score: 41.1 step: 22\n",
      "Run: 138, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 139, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 140, exploration: 0.01, score: 43.1 step: 22\n",
      "model saved\n",
      "Run: 141, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 142, exploration: 0.01, score: 37.2 step: 7\n",
      "Run: 143, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 144, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 145, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 146, exploration: 0.01, score: 39.5 step: 19\n",
      "Run: 147, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 148, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 149, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 150, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 151, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 152, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 153, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 154, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 155, exploration: 0.01, score: 40.9 step: 24\n",
      "Run: 156, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 157, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 158, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 159, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 160, exploration: 0.01, score: 42.8 step: 21\n",
      "model saved\n",
      "Run: 161, exploration: 0.01, score: 44.7 step: 32\n",
      "Run: 162, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 163, exploration: 0.01, score: 41.7 step: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 164, exploration: 0.01, score: 45.6 step: 29\n",
      "Run: 165, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 166, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 167, exploration: 0.01, score: 41.8 step: 24\n",
      "Run: 168, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 169, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 170, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 171, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 172, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 173, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 174, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 175, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 176, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 177, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 178, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 179, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 180, exploration: 0.01, score: 43.4 step: 23\n",
      "model saved\n",
      "Run: 181, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 182, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 183, exploration: 0.01, score: 36.1 step: 25\n",
      "Run: 184, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 185, exploration: 0.01, score: 41.4 step: 23\n",
      "Run: 186, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 187, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 188, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 189, exploration: 0.01, score: 36.6 step: 12\n",
      "Run: 190, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 191, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 192, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 193, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 194, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 195, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 196, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 197, exploration: 0.01, score: 40.8 step: 21\n",
      "Run: 198, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 199, exploration: 0.01, score: 40.4 step: 22\n",
      "Run: 200, exploration: 0.01, score: 40.3 step: 10\n",
      "model saved\n",
      "Run: 201, exploration: 0.01, score: 39.8 step: 26\n",
      "Run: 202, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 203, exploration: 0.01, score: 17.6 step: 43\n",
      "Run: 204, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 205, exploration: 0.01, score: 45.6 step: 29\n",
      "Run: 206, exploration: 0.01, score: 45.9 step: 30\n",
      "Run: 207, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 208, exploration: 0.01, score: 41.8 step: 24\n",
      "Run: 209, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 210, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 211, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 212, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 213, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 214, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 215, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 216, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 217, exploration: 0.01, score: 45.9 step: 30\n",
      "Run: 218, exploration: 0.01, score: 39.8 step: 3\n",
      "Run: 219, exploration: 0.01, score: 45.6 step: 29\n",
      "Run: 220, exploration: 0.01, score: 43.4 step: 23\n",
      "model saved\n",
      "Run: 221, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 222, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 223, exploration: 0.01, score: 39.8 step: 2\n",
      "Run: 224, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 225, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 226, exploration: 0.01, score: 41.3 step: 19\n",
      "Run: 227, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 228, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 229, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 230, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 231, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 232, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 233, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 234, exploration: 0.01, score: 38.8 step: 13\n",
      "Run: 235, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 236, exploration: 0.01, score: 39.8 step: 3\n",
      "Run: 237, exploration: 0.01, score: 44.7 step: 32\n",
      "Run: 238, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 239, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 240, exploration: 0.01, score: 47.1 step: 33\n",
      "model saved\n",
      "Run: 241, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 242, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 243, exploration: 0.01, score: 41.3 step: 31\n",
      "Run: 244, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 245, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 246, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 247, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 248, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 249, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 250, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 251, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 252, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 253, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 254, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 255, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 256, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 257, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 258, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 259, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 260, exploration: 0.01, score: 40.0 step: 8\n",
      "model saved\n",
      "Run: 261, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 262, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 263, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 264, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 265, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 266, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 267, exploration: 0.01, score: 46.0 step: 35\n",
      "Run: 268, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 269, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 270, exploration: 0.01, score: 38.6 step: 12\n",
      "Run: 271, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 272, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 273, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 274, exploration: 0.01, score: 39.8 step: 2\n",
      "Run: 275, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 276, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 277, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 278, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 279, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 280, exploration: 0.01, score: 41.7 step: 17\n",
      "model saved\n",
      "Run: 281, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 282, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 283, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 284, exploration: 0.01, score: 44.0 step: 32\n",
      "Run: 285, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 286, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 287, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 288, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 289, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 290, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 291, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 292, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 293, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 294, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 295, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 296, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 297, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 298, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 299, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 300, exploration: 0.01, score: 44.1 step: 25\n",
      "model saved\n",
      "Run: 301, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 302, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 303, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 304, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 305, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 306, exploration: 0.01, score: 44.3 step: 31\n",
      "Run: 307, exploration: 0.01, score: 45.6 step: 29\n",
      "Run: 308, exploration: 0.01, score: 38.8 step: 16\n",
      "Run: 309, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 310, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 311, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 312, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 313, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 314, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 315, exploration: 0.01, score: 38.0 step: 8\n",
      "Run: 316, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 317, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 318, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 319, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 320, exploration: 0.01, score: 43.1 step: 22\n",
      "model saved\n",
      "Run: 321, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 322, exploration: 0.01, score: 46.7 step: 32\n",
      "Run: 323, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 324, exploration: 0.01, score: 37.3 step: 8\n",
      "Run: 325, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 326, exploration: 0.01, score: 41.7 step: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 327, exploration: 0.01, score: 45.6 step: 29\n",
      "Run: 328, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 329, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 330, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 331, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 332, exploration: 0.01, score: 37.2 step: 7\n",
      "Run: 333, exploration: 0.01, score: 40.5 step: 20\n",
      "Run: 334, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 335, exploration: 0.01, score: 46.3 step: 31\n",
      "Run: 336, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 337, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 338, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 339, exploration: 0.01, score: 34.8 step: 27\n",
      "Run: 340, exploration: 0.01, score: 44.5 step: 26\n",
      "model saved\n",
      "Run: 341, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 342, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 343, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 344, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 345, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 346, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 347, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 348, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 349, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 350, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 351, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 352, exploration: 0.01, score: 41.9 step: 30\n",
      "Run: 353, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 354, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 355, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 356, exploration: 0.01, score: 45.1 step: 33\n",
      "Run: 357, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 358, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 359, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 360, exploration: 0.01, score: 41.2 step: 15\n",
      "model saved\n",
      "Run: 361, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 362, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 363, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 364, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 365, exploration: 0.01, score: 38.8 step: 16\n",
      "Run: 366, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 367, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 368, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 369, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 370, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 371, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 372, exploration: 0.01, score: 39.2 step: 15\n",
      "Run: 373, exploration: 0.01, score: 45.9 step: 30\n",
      "Run: 374, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 375, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 376, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 377, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 378, exploration: 0.01, score: 39.7 step: 17\n",
      "Run: 379, exploration: 0.01, score: 44.3 step: 31\n",
      "Run: 380, exploration: 0.01, score: 41.5 step: 16\n",
      "model saved\n",
      "Run: 381, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 382, exploration: 0.01, score: 44.7 step: 29\n",
      "Run: 383, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 384, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 385, exploration: 0.01, score: 43.9 step: 27\n",
      "Run: 386, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 387, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 388, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 389, exploration: 0.01, score: 41.2 step: 28\n",
      "Run: 390, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 391, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 392, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 393, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 394, exploration: 0.01, score: 40.5 step: 20\n",
      "Run: 395, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 396, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 397, exploration: 0.01, score: 42.1 step: 25\n",
      "Run: 398, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 399, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 400, exploration: 0.01, score: 40.4 step: 11\n",
      "model saved\n",
      "Run: 401, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 402, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 403, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 404, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 405, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 406, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 407, exploration: 0.01, score: 39.8 step: 3\n",
      "Run: 408, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 409, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 410, exploration: 0.01, score: 45.6 step: 29\n",
      "Run: 411, exploration: 0.01, score: 40.5 step: 20\n",
      "Run: 412, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 413, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 414, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 415, exploration: 0.01, score: -0.9 step: 50\n",
      "Run: 416, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 417, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 418, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 419, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 420, exploration: 0.01, score: 42.2 step: 19\n",
      "model saved\n",
      "Run: 421, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 422, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 423, exploration: 0.01, score: 39.0 step: 6\n",
      "Run: 424, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 425, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 426, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 427, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 428, exploration: 0.01, score: 37.7 step: 11\n",
      "Run: 429, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 430, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 431, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 432, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 433, exploration: 0.01, score: 43.9 step: 27\n",
      "Run: 434, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 435, exploration: 0.01, score: 3.0 step: 50\n",
      "Run: 436, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 437, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 438, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 439, exploration: 0.01, score: 41.6 step: 34\n",
      "Run: 440, exploration: 0.01, score: 41.7 step: 17\n",
      "model saved\n",
      "Run: 441, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 442, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 443, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 444, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 445, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 446, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 447, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 448, exploration: 0.01, score: 39.0 step: 14\n",
      "Run: 449, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 450, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 451, exploration: 0.01, score: 38.5 step: 15\n",
      "Run: 452, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 453, exploration: 0.01, score: 45.8 step: 32\n",
      "Run: 454, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 455, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 456, exploration: 0.01, score: 40.2 step: 19\n",
      "Run: 457, exploration: 0.01, score: 39.7 step: 17\n",
      "Run: 458, exploration: 0.01, score: 39.3 step: 19\n",
      "Run: 459, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 460, exploration: 0.01, score: 46.7 step: 32\n",
      "model saved\n",
      "Run: 461, exploration: 0.01, score: 33.8 step: 24\n",
      "Run: 462, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 463, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 464, exploration: 0.01, score: 39.7 step: 17\n",
      "Run: 465, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 466, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 467, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 468, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 469, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 470, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 471, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 472, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 473, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 474, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 475, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 476, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 477, exploration: 0.01, score: 40.6 step: 16\n",
      "Run: 478, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 479, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 480, exploration: 0.01, score: 41.7 step: 17\n",
      "model saved\n",
      "Run: 481, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 482, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 483, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 484, exploration: 0.01, score: 41.1 step: 24\n",
      "Run: 485, exploration: 0.01, score: 36.0 step: 18\n",
      "Run: 486, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 487, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 488, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 489, exploration: 0.01, score: 43.4 step: 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 490, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 491, exploration: 0.01, score: 38.8 step: 13\n",
      "Run: 492, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 493, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 494, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 495, exploration: 0.01, score: 41.1 step: 22\n",
      "Run: 496, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 497, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 498, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 499, exploration: 0.01, score: 44.0 step: 35\n",
      "Run: 500, exploration: 0.01, score: 41.2 step: 15\n",
      "model saved\n",
      "Run: 501, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 502, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 503, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 504, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 505, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 506, exploration: 0.01, score: 40.0 step: 18\n",
      "Run: 507, exploration: 0.01, score: 0.99 step: 50\n",
      "Run: 508, exploration: 0.01, score: 39.8 step: 2\n",
      "Run: 509, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 510, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 511, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 512, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 513, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 514, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 515, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 516, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 517, exploration: 0.01, score: 42.5 step: 26\n",
      "Run: 518, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 519, exploration: 0.01, score: 44.7 step: 32\n",
      "Run: 520, exploration: 0.01, score: 43.1 step: 22\n",
      "model saved\n",
      "Run: 521, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 522, exploration: 0.01, score: 45.6 step: 29\n",
      "Run: 523, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 524, exploration: 0.01, score: 41.1 step: 18\n",
      "Run: 525, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 526, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 527, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 528, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 529, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 530, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 531, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 532, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 533, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 534, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 535, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 536, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 537, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 538, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 539, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 540, exploration: 0.01, score: 40.4 step: 11\n",
      "model saved\n",
      "Run: 541, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 542, exploration: 0.01, score: 39.5 step: 16\n",
      "Run: 543, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 544, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 545, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 546, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 547, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 548, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 549, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 550, exploration: 0.01, score: 40.8 step: 21\n",
      "Run: 551, exploration: 0.01, score: 41.9 step: 21\n",
      "Run: 552, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 553, exploration: 0.01, score: 42.5 step: 26\n",
      "Run: 554, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 555, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 556, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 557, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 558, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 559, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 560, exploration: 0.01, score: 37.6 step: 10\n",
      "model saved\n",
      "Run: 561, exploration: 0.01, score: 39.0 step: 14\n",
      "Run: 562, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 563, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 564, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 565, exploration: 0.01, score: 45.9 step: 30\n",
      "Run: 566, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 567, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 568, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 569, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 570, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 571, exploration: 0.01, score: 41.1 step: 18\n",
      "Run: 572, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 573, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 574, exploration: 0.01, score: 46.7 step: 32\n",
      "Run: 575, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 576, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 577, exploration: 0.01, score: 45.6 step: 29\n",
      "Run: 578, exploration: 0.01, score: 40.3 step: 15\n",
      "Run: 579, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 580, exploration: 0.01, score: 39.9 step: 6\n",
      "model saved\n",
      "Run: 581, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 582, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 583, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 584, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 585, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 586, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 587, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 588, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 589, exploration: 0.01, score: 46.7 step: 32\n",
      "Run: 590, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 591, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 592, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 593, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 594, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 595, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 596, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 597, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 598, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 599, exploration: 0.01, score: 39.2 step: 9\n",
      "Run: 600, exploration: 0.01, score: 39.8 step: 5\n",
      "model saved\n",
      "Run: 601, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 602, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 603, exploration: 0.01, score: 41.9 step: 21\n",
      "Run: 604, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 605, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 606, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 607, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 608, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 609, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 610, exploration: 0.01, score: 38.6 step: 12\n",
      "Run: 611, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 612, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 613, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 614, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 615, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 616, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 617, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 618, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 619, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 620, exploration: 0.01, score: 42.2 step: 19\n",
      "model saved\n",
      "Run: 621, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 622, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 623, exploration: 0.01, score: 40.2 step: 19\n",
      "Run: 624, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 625, exploration: 0.01, score: 39.3 step: 18\n",
      "Run: 626, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 627, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 628, exploration: 0.01, score: 29.6 step: 43\n",
      "Run: 629, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 630, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 631, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 632, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 633, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 634, exploration: 0.01, score: 39.7 step: 17\n",
      "Run: 635, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 636, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 637, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 638, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 639, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 640, exploration: 0.01, score: 41.0 step: 14\n",
      "model saved\n",
      "Run: 641, exploration: 0.01, score: 39.0 step: 14\n",
      "Run: 642, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 643, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 644, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 645, exploration: 0.01, score: 24.2 step: 28\n",
      "Run: 646, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 647, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 648, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 649, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 650, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 651, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 652, exploration: 0.01, score: 41.7 step: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 653, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 654, exploration: 0.01, score: 39.8 step: 2\n",
      "Run: 655, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 656, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 657, exploration: 0.01, score: 39.8 step: 2\n",
      "Run: 658, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 659, exploration: 0.01, score: 41.8 step: 24\n",
      "Run: 660, exploration: 0.01, score: 44.8 step: 27\n",
      "model saved\n",
      "Run: 661, exploration: 0.01, score: 45.6 step: 29\n",
      "Run: 662, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 663, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 664, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 665, exploration: 0.01, score: 42.1 step: 25\n",
      "Run: 666, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 667, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 668, exploration: 0.01, score: 40.0 step: 18\n",
      "Run: 669, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 670, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 671, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 672, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 673, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 674, exploration: 0.01, score: 24.7 step: 32\n",
      "Run: 675, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 676, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 677, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 678, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 679, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 680, exploration: 0.01, score: 42.8 step: 21\n",
      "model saved\n",
      "Run: 681, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 682, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 683, exploration: 0.01, score: 41.6 step: 20\n",
      "Run: 684, exploration: 0.01, score: 40.4 step: 22\n",
      "Run: 685, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 686, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 687, exploration: 0.01, score: 39.8 step: 3\n",
      "Run: 688, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 689, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 690, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 691, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 692, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 693, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 694, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 695, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 696, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 697, exploration: 0.01, score: 37.9 step: 12\n",
      "Run: 698, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 699, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 700, exploration: 0.01, score: 39.8 step: 5\n",
      "model saved\n",
      "Run: 701, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 702, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 703, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 704, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 705, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 706, exploration: 0.01, score: 46.7 step: 32\n",
      "Run: 707, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 708, exploration: 0.01, score: 45.9 step: 30\n",
      "Run: 709, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 710, exploration: 0.01, score: 45.9 step: 30\n",
      "Run: 711, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 712, exploration: 0.01, score: 43.2 step: 25\n",
      "Run: 713, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 714, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 715, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 716, exploration: 0.01, score: 44.7 step: 32\n",
      "Run: 717, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 718, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 719, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 720, exploration: 0.01, score: 41.2 step: 15\n",
      "model saved\n",
      "Run: 721, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 722, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 723, exploration: 0.01, score: 40.4 step: 22\n",
      "Run: 724, exploration: 0.01, score: 45.6 step: 29\n",
      "Run: 725, exploration: 0.01, score: 42.4 step: 33\n",
      "Run: 726, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 727, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 728, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 729, exploration: 0.01, score: 43.9 step: 30\n",
      "Run: 730, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 731, exploration: 0.01, score: 46.3 step: 31\n",
      "Run: 732, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 733, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 734, exploration: 0.01, score: 39.9 step: 13\n",
      "Run: 735, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 736, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 737, exploration: 0.01, score: 39.8 step: 3\n",
      "Run: 738, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 739, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 740, exploration: 0.01, score: 40.4 step: 11\n",
      "model saved\n",
      "Run: 741, exploration: 0.01, score: 39.3 step: 18\n",
      "Run: 742, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 743, exploration: 0.01, score: 45.9 step: 30\n",
      "Run: 744, exploration: 0.01, score: 39.9 step: 1\n",
      "Run: 745, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 746, exploration: 0.01, score: 42.9 step: 24\n",
      "Run: 747, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 748, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 749, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 750, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 751, exploration: 0.01, score: 42.9 step: 24\n",
      "Run: 752, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 753, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 754, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 755, exploration: 0.01, score: 38.5 step: 28\n",
      "Run: 756, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 757, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 758, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 759, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 760, exploration: 0.01, score: 39.8 step: 3\n",
      "model saved\n",
      "Run: 761, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 762, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 763, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 764, exploration: 0.01, score: 40.8 step: 17\n",
      "Run: 765, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 766, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 767, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 768, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 769, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 770, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 771, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 772, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 773, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 774, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 775, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 776, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 777, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 778, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 779, exploration: 0.01, score: 38.6 step: 16\n",
      "Run: 780, exploration: 0.01, score: 39.8 step: 4\n",
      "model saved\n",
      "Run: 781, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 782, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 783, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 784, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 785, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 786, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 787, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 788, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 789, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 790, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 791, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 792, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 793, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 794, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 795, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 796, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 797, exploration: 0.01, score: 39.7 step: 17\n",
      "Run: 798, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 799, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 800, exploration: 0.01, score: 41.0 step: 14\n",
      "model saved\n",
      "Run: 801, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 802, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 803, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 804, exploration: 0.01, score: 46.3 step: 31\n",
      "Run: 805, exploration: 0.01, score: 45.9 step: 30\n",
      "Run: 806, exploration: 0.01, score: 45.6 step: 29\n",
      "Run: 807, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 808, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 809, exploration: 0.01, score: 39.8 step: 3\n",
      "Run: 810, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 811, exploration: 0.01, score: 39.8 step: 3\n",
      "Run: 812, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 813, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 814, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 815, exploration: 0.01, score: 42.5 step: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 816, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 817, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 818, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 819, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 820, exploration: 0.01, score: 42.2 step: 19\n",
      "model saved\n",
      "Run: 821, exploration: 0.01, score: 37.8 step: 2\n",
      "Run: 822, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 823, exploration: 0.01, score: 44.7 step: 32\n",
      "Run: 824, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 825, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 826, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 827, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 828, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 829, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 830, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 831, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 832, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 833, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 834, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 835, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 836, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 837, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 838, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 839, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 840, exploration: 0.01, score: 44.8 step: 27\n",
      "model saved\n",
      "Run: 841, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 842, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 843, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 844, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 845, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 846, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 847, exploration: 0.01, score: 47.1 step: 33\n",
      "Run: 848, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 849, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 850, exploration: 0.01, score: 39.8 step: 2\n",
      "Run: 851, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 852, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 853, exploration: 0.01, score: 45.6 step: 29\n",
      "Run: 854, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 855, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 856, exploration: 0.01, score: 39.4 step: 23\n",
      "Run: 857, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 858, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 859, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 860, exploration: 0.01, score: 39.5 step: 16\n",
      "model saved\n",
      "Run: 861, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 862, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 863, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 864, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 865, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 866, exploration: 0.01, score: 40.1 step: 21\n",
      "Run: 867, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 868, exploration: 0.01, score: 46.3 step: 31\n",
      "Run: 869, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 870, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 871, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 872, exploration: 0.01, score: 38.8 step: 13\n",
      "Run: 873, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 874, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 875, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 876, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 877, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 878, exploration: 0.01, score: 36.2 step: 33\n",
      "Run: 879, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 880, exploration: 0.01, score: 42.0 step: 18\n",
      "model saved\n",
      "Run: 881, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 882, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 883, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 884, exploration: 0.01, score: 43.2 step: 25\n",
      "Run: 885, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 886, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 887, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 888, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 889, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 890, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 891, exploration: 0.01, score: 41.2 step: 25\n",
      "Run: 892, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 893, exploration: 0.01, score: 42.5 step: 26\n",
      "Run: 894, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 895, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 896, exploration: 0.01, score: 39.2 step: 15\n",
      "Run: 897, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 898, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 899, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 900, exploration: 0.01, score: 41.5 step: 16\n",
      "model saved\n",
      "Run: 901, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 902, exploration: 0.01, score: 41.4 step: 23\n",
      "Run: 903, exploration: 0.01, score: 40.5 step: 20\n",
      "Run: 904, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 905, exploration: 0.01, score: 39.0 step: 17\n",
      "Run: 906, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 907, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 908, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 909, exploration: 0.01, score: 39.6 step: 34\n",
      "Run: 910, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 911, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 912, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 913, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 914, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 915, exploration: 0.01, score: 39.5 step: 16\n",
      "Run: 916, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 917, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 918, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 919, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 920, exploration: 0.01, score: 41.5 step: 16\n",
      "model saved\n",
      "Run: 921, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 922, exploration: 0.01, score: 39.8 step: 2\n",
      "Run: 923, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 924, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 925, exploration: 0.01, score: 32.8 step: 21\n",
      "Run: 926, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 927, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 928, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 929, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 930, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 931, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 932, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 933, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 934, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 935, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 936, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 937, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 938, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 939, exploration: 0.01, score: 39.8 step: 2\n",
      "Run: 940, exploration: 0.01, score: 44.1 step: 25\n",
      "model saved\n",
      "Run: 941, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 942, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 943, exploration: 0.01, score: 39.8 step: 2\n",
      "Run: 944, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 945, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 946, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 947, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 948, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 949, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 950, exploration: 0.01, score: 39.7 step: 17\n",
      "Run: 951, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 952, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 953, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 954, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 955, exploration: 0.01, score: 39.0 step: 14\n",
      "Run: 956, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 957, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 958, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 959, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 960, exploration: 0.01, score: 44.1 step: 25\n",
      "model saved\n",
      "Run: 961, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 962, exploration: 0.01, score: 39.9 step: 1\n",
      "Run: 963, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 964, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 965, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 966, exploration: 0.01, score: 41.1 step: 22\n",
      "Run: 967, exploration: 0.01, score: 46.7 step: 32\n",
      "Run: 968, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 969, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 970, exploration: 0.01, score: 42.0 step: 35\n",
      "Run: 971, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 972, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 973, exploration: 0.01, score: 42.9 step: 24\n",
      "Run: 974, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 975, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 976, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 977, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 978, exploration: 0.01, score: 38.5 step: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 979, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 980, exploration: 0.01, score: 42.8 step: 21\n",
      "model saved\n",
      "Run: 981, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 982, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 983, exploration: 0.01, score: 41.1 step: 18\n",
      "Run: 984, exploration: 0.01, score: 41.8 step: 24\n",
      "Run: 985, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 986, exploration: 0.01, score: 40.0 step: 18\n",
      "Run: 987, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 988, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 989, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 990, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 991, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 992, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 993, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 994, exploration: 0.01, score: 39.1 step: 24\n",
      "Run: 995, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 996, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 997, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 998, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 999, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1000, exploration: 0.01, score: 39.9 step: 6\n",
      "model saved\n",
      "Run: 1001, exploration: 0.01, score: 39.7 step: 17\n",
      "Run: 1002, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 1003, exploration: 0.01, score: 37.8 step: 2\n",
      "Run: 1004, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1005, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1006, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1007, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1008, exploration: 0.01, score: 41.4 step: 23\n",
      "Run: 1009, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1010, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1011, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1012, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1013, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1014, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 1015, exploration: 0.01, score: 40.5 step: 20\n",
      "Run: 1016, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1017, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 1018, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1019, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1020, exploration: 0.01, score: 40.8 step: 13\n",
      "model saved\n",
      "Run: 1021, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 1022, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1023, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1024, exploration: 0.01, score: 42.5 step: 23\n",
      "Run: 1025, exploration: 0.01, score: 41.1 step: 22\n",
      "Run: 1026, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 1027, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1028, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1029, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 1030, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1031, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 1032, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1033, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 1034, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1035, exploration: 0.01, score: -2.9 step: 50\n",
      "Run: 1036, exploration: 0.01, score: 43.9 step: 27\n",
      "Run: 1037, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1038, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1039, exploration: 0.01, score: 39.5 step: 16\n",
      "Run: 1040, exploration: 0.01, score: 39.7 step: 17\n",
      "model saved\n",
      "Run: 1041, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1042, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 1043, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1044, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1045, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1046, exploration: 0.01, score: 40.8 step: 21\n",
      "Run: 1047, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1048, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1049, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 1050, exploration: 0.01, score: 37.2 step: 15\n",
      "Run: 1051, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 1052, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 1053, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 1054, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1055, exploration: 0.01, score: 39.8 step: 3\n",
      "Run: 1056, exploration: 0.01, score: 38.1 step: 25\n",
      "Run: 1057, exploration: 0.01, score: 37.9 step: 6\n",
      "Run: 1058, exploration: 0.01, score: -13. step: 50\n",
      "Run: 1059, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1060, exploration: 0.01, score: 44.5 step: 26\n",
      "model saved\n",
      "Run: 1061, exploration: 0.01, score: 45.6 step: 29\n",
      "Run: 1062, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1063, exploration: 0.01, score: 30.4 step: 36\n",
      "Run: 1064, exploration: 0.01, score: 37.4 step: 23\n",
      "Run: 1065, exploration: 0.01, score: 39.8 step: 3\n",
      "Run: 1066, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1067, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 1068, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 1069, exploration: 0.01, score: 23.8 step: 28\n",
      "Run: 1070, exploration: 0.01, score: 46.3 step: 31\n",
      "Run: 1071, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1072, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 1073, exploration: 0.01, score: 41.6 step: 20\n",
      "Run: 1074, exploration: 0.01, score: 32.5 step: 26\n",
      "Run: 1075, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1076, exploration: 0.01, score: 38.6 step: 12\n",
      "Run: 1077, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1078, exploration: 0.01, score: 39.1 step: 8\n",
      "Run: 1079, exploration: 0.01, score: 40.5 step: 20\n",
      "Run: 1080, exploration: 0.01, score: 44.8 step: 27\n",
      "model saved\n",
      "Run: 1081, exploration: 0.01, score: 26.0 step: 46\n",
      "Run: 1082, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 1083, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 1084, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1085, exploration: 0.01, score: 40.8 step: 17\n",
      "Run: 1086, exploration: 0.01, score: 38.6 step: 12\n",
      "Run: 1087, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1088, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 1089, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 1090, exploration: 0.01, score: 40.5 step: 20\n",
      "Run: 1091, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1092, exploration: 0.01, score: 43.9 step: 30\n",
      "Run: 1093, exploration: 0.01, score: 38.4 step: 11\n",
      "Run: 1094, exploration: 0.01, score: 40.1 step: 25\n",
      "Run: 1095, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 1096, exploration: 0.01, score: 46.3 step: 31\n",
      "Run: 1097, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 1098, exploration: 0.01, score: 43.6 step: 34\n",
      "Run: 1099, exploration: 0.01, score: 41.8 step: 26\n",
      "Run: 1100, exploration: 0.01, score: 40.0 step: 18\n",
      "model saved\n",
      "Run: 1101, exploration: 0.01, score: 46.3 step: 31\n",
      "Run: 1102, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 1103, exploration: 0.01, score: 39.5 step: 16\n",
      "Run: 1104, exploration: 0.01, score: 43.8 step: 34\n",
      "Run: 1105, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 1106, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1107, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 1108, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 1109, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1110, exploration: 0.01, score: 38.5 step: 20\n",
      "Run: 1111, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1112, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 1113, exploration: 0.01, score: -15. step: 50\n",
      "Run: 1114, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1115, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1116, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1117, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1118, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 1119, exploration: 0.01, score: 40.5 step: 20\n",
      "Run: 1120, exploration: 0.01, score: 39.9 step: 7\n",
      "model saved\n",
      "Run: 1121, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1122, exploration: 0.01, score: -13. step: 50\n",
      "Run: 1123, exploration: 0.01, score: 39.7 step: 17\n",
      "Run: 1124, exploration: 0.01, score: 42.8 step: 27\n",
      "Run: 1125, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1126, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1127, exploration: 0.01, score: 41.2 step: 28\n",
      "Run: 1128, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1129, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 1130, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1131, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 1132, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 1133, exploration: 0.01, score: 40.2 step: 19\n",
      "Run: 1134, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 1135, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 1136, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1137, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1138, exploration: 0.01, score: 43.4 step: 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1139, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 1140, exploration: 0.01, score: 33.1 step: 33\n",
      "model saved\n",
      "Run: 1141, exploration: 0.01, score: -9.0 step: 50\n",
      "Run: 1142, exploration: 0.01, score: 39.8 step: 2\n",
      "Run: 1143, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 1144, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1145, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1146, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 1147, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1148, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1149, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 1150, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1151, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 1152, exploration: 0.01, score: 46.3 step: 31\n",
      "Run: 1153, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1154, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1155, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 1156, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 1157, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1158, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1159, exploration: 0.01, score: 38.2 step: 42\n",
      "Run: 1160, exploration: 0.01, score: 41.7 step: 17\n",
      "model saved\n",
      "Run: 1161, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 1162, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1163, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1164, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 1165, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1166, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 1167, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1168, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1169, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1170, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 1171, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1172, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1173, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1174, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 1175, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1176, exploration: 0.01, score: 41.3 step: 19\n",
      "Run: 1177, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1178, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 1179, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1180, exploration: 0.01, score: 43.4 step: 23\n",
      "model saved\n",
      "Run: 1181, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 1182, exploration: 0.01, score: 41.8 step: 24\n",
      "Run: 1183, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 1184, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1185, exploration: 0.01, score: 45.9 step: 30\n",
      "Run: 1186, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 1187, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1188, exploration: 0.01, score: 38.3 step: 14\n",
      "Run: 1189, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1190, exploration: 0.01, score: 40.2 step: 19\n",
      "Run: 1191, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1192, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 1193, exploration: 0.01, score: 45.6 step: 29\n",
      "Run: 1194, exploration: 0.01, score: 40.3 step: 15\n",
      "Run: 1195, exploration: 0.01, score: 40.4 step: 22\n",
      "Run: 1196, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1197, exploration: 0.01, score: 41.8 step: 26\n",
      "Run: 1198, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1199, exploration: 0.01, score: 41.9 step: 21\n",
      "Run: 1200, exploration: 0.01, score: 45.6 step: 29\n",
      "model saved\n",
      "Run: 1201, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1202, exploration: 0.01, score: 45.9 step: 30\n",
      "Run: 1203, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1204, exploration: 0.01, score: 39.0 step: 17\n",
      "Run: 1205, exploration: 0.01, score: 39.7 step: 12\n",
      "Run: 1206, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1207, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1208, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1209, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1210, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 1211, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 1212, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 1213, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 1214, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 1215, exploration: 0.01, score: 44.7 step: 32\n",
      "Run: 1216, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1217, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1218, exploration: 0.01, score: 39.8 step: 3\n",
      "Run: 1219, exploration: 0.01, score: 45.9 step: 30\n",
      "Run: 1220, exploration: 0.01, score: 40.8 step: 13\n",
      "model saved\n",
      "Run: 1221, exploration: 0.01, score: 39.0 step: 14\n",
      "Run: 1222, exploration: 0.01, score: 43.2 step: 28\n",
      "Run: 1223, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1224, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1225, exploration: 0.01, score: 41.4 step: 23\n",
      "Run: 1226, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 1227, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1228, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1229, exploration: 0.01, score: 40.5 step: 25\n",
      "Run: 1230, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1231, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 1232, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1233, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1234, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1235, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1236, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 1237, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1238, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1239, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1240, exploration: 0.01, score: 42.5 step: 20\n",
      "model saved\n",
      "Run: 1241, exploration: 0.01, score: 46.7 step: 32\n",
      "Run: 1242, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 1243, exploration: 0.01, score: 37.1 step: 4\n",
      "Run: 1244, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1245, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 1246, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1247, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 1248, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 1249, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 1250, exploration: 0.01, score: 39.1 step: 33\n",
      "Run: 1251, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1252, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 1253, exploration: 0.01, score: 47.6 step: 34\n",
      "Run: 1254, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 1255, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1256, exploration: 0.01, score: 43.2 step: 28\n",
      "Run: 1257, exploration: 0.01, score: 37.9 step: 7\n",
      "Run: 1258, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 1259, exploration: 0.01, score: 44.3 step: 31\n",
      "Run: 1260, exploration: 0.01, score: 41.7 step: 17\n",
      "model saved\n",
      "Run: 1261, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 1262, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1263, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 1264, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 1265, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 1266, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1267, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 1268, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1269, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 1270, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1271, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1272, exploration: 0.01, score: 41.3 step: 19\n",
      "Run: 1273, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1274, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1275, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1276, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1277, exploration: 0.01, score: 36.1 step: 27\n",
      "Run: 1278, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1279, exploration: 0.01, score: 40.3 step: 31\n",
      "Run: 1280, exploration: 0.01, score: 43.1 step: 22\n",
      "model saved\n",
      "Run: 1281, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1282, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 1283, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1284, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1285, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 1286, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1287, exploration: 0.01, score: 37.9 step: 12\n",
      "Run: 1288, exploration: 0.01, score: 41.1 step: 22\n",
      "Run: 1289, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1290, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1291, exploration: 0.01, score: 39.8 step: 2\n",
      "Run: 1292, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 1293, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1294, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 1295, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1296, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1297, exploration: 0.01, score: 42.5 step: 28\n",
      "Run: 1298, exploration: 0.01, score: 42.0 step: 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1299, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 1300, exploration: 0.01, score: 39.8 step: 5\n",
      "model saved\n",
      "Run: 1301, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1302, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1303, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 1304, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 1305, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1306, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1307, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1308, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 1309, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1310, exploration: 0.01, score: 44.9 step: 32\n",
      "Run: 1311, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1312, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 1313, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1314, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 1315, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 1316, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 1317, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1318, exploration: 0.01, score: 34.3 step: 31\n",
      "Run: 1319, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1320, exploration: 0.01, score: 40.4 step: 11\n",
      "model saved\n",
      "Run: 1321, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1322, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1323, exploration: 0.01, score: 39.8 step: 2\n",
      "Run: 1324, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 1325, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1326, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1327, exploration: 0.01, score: 46.3 step: 31\n",
      "Run: 1328, exploration: 0.01, score: 40.0 step: 18\n",
      "Run: 1329, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1330, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1331, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 1332, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 1333, exploration: 0.01, score: 40.8 step: 17\n",
      "Run: 1334, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1335, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 1336, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1337, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 1338, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1339, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1340, exploration: 0.01, score: 40.0 step: 18\n",
      "model saved\n",
      "Run: 1341, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1342, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 1343, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1344, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1345, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1346, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1347, exploration: 0.01, score: 47.1 step: 33\n",
      "Run: 1348, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1349, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1350, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 1351, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 1352, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1353, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 1354, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1355, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1356, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 1357, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 1358, exploration: 0.01, score: 26.8 step: 21\n",
      "Run: 1359, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1360, exploration: 0.01, score: 39.9 step: 7\n",
      "model saved\n",
      "Run: 1361, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1362, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1363, exploration: 0.01, score: 45.9 step: 30\n",
      "Run: 1364, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1365, exploration: 0.01, score: 40.1 step: 21\n",
      "Run: 1366, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1367, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1368, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1369, exploration: 0.01, score: 39.3 step: 38\n",
      "Run: 1370, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1371, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1372, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 1373, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 1374, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1375, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 1376, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 1377, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1378, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1379, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1380, exploration: 0.01, score: 41.8 step: 24\n",
      "model saved\n",
      "Run: 1381, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1382, exploration: 0.01, score: 32.4 step: 36\n",
      "Run: 1383, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1384, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 1385, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1386, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1387, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 1388, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1389, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1390, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 1391, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1392, exploration: 0.01, score: 41.4 step: 23\n",
      "Run: 1393, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1394, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 1395, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1396, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1397, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1398, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 1399, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 1400, exploration: 0.01, score: 43.8 step: 24\n",
      "model saved\n",
      "Run: 1401, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 1402, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1403, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1404, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1405, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 1406, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1407, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1408, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 1409, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1410, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 1411, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1412, exploration: 0.01, score: 39.2 step: 15\n",
      "Run: 1413, exploration: 0.01, score: 41.3 step: 19\n",
      "Run: 1414, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1415, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 1416, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1417, exploration: 0.01, score: 40.5 step: 20\n",
      "Run: 1418, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 1419, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 1420, exploration: 0.01, score: 40.1 step: 9\n",
      "model saved\n",
      "Run: 1421, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1422, exploration: 0.01, score: 45.9 step: 30\n",
      "Run: 1423, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1424, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1425, exploration: 0.01, score: 47.6 step: 34\n",
      "Run: 1426, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1427, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 1428, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1429, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 1430, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1431, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1432, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1433, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 1434, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1435, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 1436, exploration: 0.01, score: 42.5 step: 23\n",
      "Run: 1437, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 1438, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 1439, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1440, exploration: 0.01, score: 40.3 step: 10\n",
      "model saved\n",
      "Run: 1441, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1442, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 1443, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1444, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1445, exploration: 0.01, score: 47.1 step: 33\n",
      "Run: 1446, exploration: 0.01, score: 40.5 step: 20\n",
      "Run: 1447, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 1448, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1449, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1450, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1451, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1452, exploration: 0.01, score: 47.5 step: 36\n",
      "Run: 1453, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1454, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1455, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 1456, exploration: 0.01, score: 47.1 step: 33\n",
      "Run: 1457, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1458, exploration: 0.01, score: 39.9 step: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1459, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1460, exploration: 0.01, score: 41.5 step: 16\n",
      "model saved\n",
      "Run: 1461, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 1462, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1463, exploration: 0.01, score: 39.5 step: 16\n",
      "Run: 1464, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 1465, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1466, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 1467, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1468, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1469, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1470, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 1471, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1472, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 1473, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1474, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 1475, exploration: 0.01, score: 45.6 step: 29\n",
      "Run: 1476, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1477, exploration: 0.01, score: 40.4 step: 22\n",
      "Run: 1478, exploration: 0.01, score: -3.0 step: 50\n",
      "Run: 1479, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1480, exploration: 0.01, score: 40.4 step: 11\n",
      "model saved\n",
      "Run: 1481, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1482, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1483, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1484, exploration: 0.01, score: 41.9 step: 21\n",
      "Run: 1485, exploration: 0.01, score: 41.1 step: 22\n",
      "Run: 1486, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1487, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1488, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 1489, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1490, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 1491, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1492, exploration: 0.01, score: 36.7 step: 23\n",
      "Run: 1493, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1494, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1495, exploration: 0.01, score: 40.9 step: 26\n",
      "Run: 1496, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 1497, exploration: 0.01, score: 45.6 step: 29\n",
      "Run: 1498, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1499, exploration: 0.01, score: 46.7 step: 32\n",
      "Run: 1500, exploration: 0.01, score: 40.6 step: 12\n",
      "model saved\n",
      "Run: 1501, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1502, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1503, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1504, exploration: 0.01, score: 45.6 step: 29\n",
      "Run: 1505, exploration: 0.01, score: 39.0 step: 14\n",
      "Run: 1506, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1507, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1508, exploration: 0.01, score: 35.4 step: 9\n",
      "Run: 1509, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1510, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 1511, exploration: 0.01, score: 41.1 step: 33\n",
      "Run: 1512, exploration: 0.01, score: 39.2 step: 15\n",
      "Run: 1513, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 1514, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1515, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1516, exploration: 0.01, score: 41.4 step: 23\n",
      "Run: 1517, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 1518, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1519, exploration: 0.01, score: 41.6 step: 29\n",
      "Run: 1520, exploration: 0.01, score: 40.0 step: 8\n",
      "model saved\n",
      "Run: 1521, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1522, exploration: 0.01, score: 39.6 step: 20\n",
      "Run: 1523, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 1524, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1525, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1526, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 1527, exploration: 0.01, score: 48.0 step: 35\n",
      "Run: 1528, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 1529, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1530, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1531, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1532, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 1533, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1534, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 1535, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 1536, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1537, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1538, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 1539, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1540, exploration: 0.01, score: 39.9 step: 7\n",
      "model saved\n",
      "Run: 1541, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1542, exploration: 0.01, score: 40.0 step: 18\n",
      "Run: 1543, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1544, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1545, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1546, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1547, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1548, exploration: 0.01, score: 45.9 step: 30\n",
      "Run: 1549, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1550, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1551, exploration: 0.01, score: 40.1 step: 25\n",
      "Run: 1552, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1553, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1554, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1555, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 1556, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 1557, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 1558, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 1559, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1560, exploration: 0.01, score: 40.3 step: 10\n",
      "model saved\n",
      "Run: 1561, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1562, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1563, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 1564, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1565, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1566, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1567, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1568, exploration: 0.01, score: 45.9 step: 30\n",
      "Run: 1569, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1570, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1571, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1572, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 1573, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 1574, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1575, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1576, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 1577, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1578, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1579, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1580, exploration: 0.01, score: 43.8 step: 24\n",
      "model saved\n",
      "Run: 1581, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1582, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 1583, exploration: 0.01, score: 41.3 step: 22\n",
      "Run: 1584, exploration: 0.01, score: 19.0 step: 50\n",
      "Run: 1585, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1586, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 1587, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1588, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1589, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1590, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1591, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1592, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1593, exploration: 0.01, score: 45.9 step: 30\n",
      "Run: 1594, exploration: 0.01, score: 39.8 step: 2\n",
      "Run: 1595, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1596, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1597, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 1598, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1599, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1600, exploration: 0.01, score: 42.5 step: 20\n",
      "model saved\n",
      "Run: 1601, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 1602, exploration: 0.01, score: 42.2 step: 28\n",
      "Run: 1603, exploration: 0.01, score: 41.1 step: 22\n",
      "Run: 1604, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 1605, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 1606, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 1607, exploration: 0.01, score: 45.6 step: 29\n",
      "Run: 1608, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1609, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 1610, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1611, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 1612, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1613, exploration: 0.01, score: 44.1 step: 25\n",
      "Run: 1614, exploration: 0.01, score: 40.8 step: 21\n",
      "Run: 1615, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1616, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1617, exploration: 0.01, score: 40.2 step: 19\n",
      "Run: 1618, exploration: 0.01, score: 41.7 step: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1619, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1620, exploration: 0.01, score: 42.8 step: 21\n",
      "model saved\n",
      "Run: 1621, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 1622, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1623, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 1624, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1625, exploration: 0.01, score: 43.2 step: 28\n",
      "Run: 1626, exploration: 0.01, score: 39.5 step: 16\n",
      "Run: 1627, exploration: 0.01, score: 39.8 step: 4\n",
      "Run: 1628, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1629, exploration: 0.01, score: 42.5 step: 26\n",
      "Run: 1630, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1631, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1632, exploration: 0.01, score: 38.0 step: 8\n",
      "Run: 1633, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1634, exploration: 0.01, score: 45.8 step: 32\n",
      "Run: 1635, exploration: 0.01, score: 40.4 step: 11\n",
      "Run: 1636, exploration: 0.01, score: 41.4 step: 23\n",
      "Run: 1637, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1638, exploration: 0.01, score: 42.5 step: 26\n",
      "Run: 1639, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 1640, exploration: 0.01, score: 38.8 step: 13\n",
      "model saved\n",
      "Run: 1641, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1642, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1643, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1644, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1645, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 1646, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 1647, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 1648, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1649, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 1650, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 1651, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1652, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 1653, exploration: 0.01, score: 44.5 step: 26\n",
      "Run: 1654, exploration: 0.01, score: 39.9 step: 7\n",
      "Run: 1655, exploration: 0.01, score: 42.1 step: 25\n",
      "Run: 1656, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1657, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 1658, exploration: 0.01, score: 40.2 step: 19\n",
      "Run: 1659, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1660, exploration: 0.01, score: 41.2 step: 15\n",
      "model saved\n",
      "Run: 1661, exploration: 0.01, score: 39.7 step: 12\n",
      "Run: 1662, exploration: 0.01, score: 43.1 step: 22\n",
      "Run: 1663, exploration: 0.01, score: 41.4 step: 25\n",
      "Run: 1664, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1665, exploration: 0.01, score: 37.9 step: 7\n",
      "Run: 1666, exploration: 0.01, score: 42.1 step: 25\n",
      "Run: 1667, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1668, exploration: 0.01, score: 45.6 step: 29\n",
      "Run: 1669, exploration: 0.01, score: 39.8 step: 5\n",
      "Run: 1670, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1671, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1672, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1673, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 1674, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1675, exploration: 0.01, score: 39.9 step: 1\n",
      "Run: 1676, exploration: 0.01, score: 44.8 step: 27\n",
      "Run: 1677, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1678, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1679, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1680, exploration: 0.01, score: 41.7 step: 17\n",
      "model saved\n",
      "Run: 1681, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1682, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 1683, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 1684, exploration: 0.01, score: 45.6 step: 29\n",
      "Run: 1685, exploration: 0.01, score: 41.1 step: 22\n",
      "Run: 1686, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 1687, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 1688, exploration: 0.01, score: 44.7 step: 32\n",
      "Run: 1689, exploration: 0.01, score: 41.2 step: 15\n",
      "Run: 1690, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1691, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 1692, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1693, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1694, exploration: 0.01, score: 45.9 step: 30\n",
      "Run: 1695, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1696, exploration: 0.01, score: -33. step: 50\n",
      "Run: 1697, exploration: 0.01, score: 41.0 step: 14\n",
      "Run: 1698, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1699, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1700, exploration: 0.01, score: 43.8 step: 29\n",
      "model saved\n",
      "Run: 1701, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1702, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1703, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 1704, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1705, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1706, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1707, exploration: 0.01, score: 45.1 step: 33\n",
      "Run: 1708, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 1709, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 1710, exploration: 0.01, score: 39.9 step: 6\n",
      "Run: 1711, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1712, exploration: 0.01, score: 43.6 step: 26\n",
      "Run: 1713, exploration: 0.01, score: 40.6 step: 16\n",
      "Run: 1714, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1715, exploration: 0.01, score: 40.8 step: 13\n",
      "Run: 1716, exploration: 0.01, score: 42.5 step: 26\n",
      "Run: 1717, exploration: 0.01, score: -5.9 step: 48\n",
      "Run: 1718, exploration: 0.01, score: 43.8 step: 24\n",
      "Run: 1719, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1720, exploration: 0.01, score: 41.2 step: 15\n",
      "model saved\n",
      "Run: 1721, exploration: 0.01, score: 42.8 step: 21\n",
      "Run: 1722, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1723, exploration: 0.01, score: 40.6 step: 12\n",
      "Run: 1724, exploration: 0.01, score: 45.2 step: 28\n",
      "Run: 1725, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1726, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1727, exploration: 0.01, score: 42.5 step: 20\n",
      "Run: 1728, exploration: 0.01, score: 40.1 step: 9\n",
      "Run: 1729, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1730, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1731, exploration: 0.01, score: 47.1 step: 33\n",
      "Run: 1732, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1733, exploration: 0.01, score: 42.2 step: 19\n",
      "Run: 1734, exploration: 0.01, score: 40.0 step: 8\n",
      "Run: 1735, exploration: 0.01, score: 40.3 step: 10\n",
      "Run: 1736, exploration: 0.01, score: 41.5 step: 16\n",
      "Run: 1737, exploration: 0.01, score: 42.0 step: 18\n",
      "Run: 1738, exploration: 0.01, score: 41.7 step: 17\n",
      "Run: 1739, exploration: 0.01, score: 43.4 step: 23\n",
      "Run: 1740, exploration: 0.01, score: 41.2 step: 15\n",
      "model saved\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-248ed2b3dfa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0mcartpole\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;31m#cartpole_test()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-248ed2b3dfa0>\u001b[0m in \u001b[0;36mcartpole\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdqn_solver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mobserve_past\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;31m#reward = reward if not terminal else -reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mstate_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_space\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/folder/public_transport/GridWorld/environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/folder/public_transport/GridWorld/environment.py\u001b[0m in \u001b[0;36mrun_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m                   \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_missed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_achieved\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                   \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_second\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_performed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                   (self.total_reward), debug_mode=(self.debug_mode))\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_pos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_pos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/folder/public_transport/GridWorld/frame_runner.py\u001b[0m in \u001b[0;36mrunner\u001b[0;34m(grid, agent_pos, target_pos, timestep, transport_timetable, n_missed, n_achieved, n_iteration, frame_second, reward_action, possible_reward, action_performed, total_reward, debug_mode)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missed: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_missed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Achieved: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_achieved\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reward_action: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m550\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total_reword: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m700\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/folder/public_transport/GridWorld/frame_runner.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(text, x, y)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFont\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'freesansbold.ttf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWHITE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mtextRect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_rect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lorenzo_env/lib/python3.6/site-packages/pygame/pkgdata.py\u001b[0m in \u001b[0;36mgetResource\u001b[0;34m(identifier, pkgname)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mgetResource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkgname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \"\"\"\n\u001b[1;32m     36\u001b[0m     \u001b[0mAcquire\u001b[0m \u001b[0ma\u001b[0m \u001b[0mreadable\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mpackage\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "\n",
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 10\n",
    "import os\n",
    "\n",
    "ENV_NAME = \"CartPole-v1\"\n",
    "\n",
    "GAMMA = 0.1\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "MEMORY_SIZE = 100000\n",
    "MIN_MEMORY_SIZE = 2000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "EXPLORATION_MAX = 1.0\n",
    "EXPLORATION_MIN = 0.01\n",
    "EXPLORATION_DECAY = 0.9995\n",
    "\n",
    "from environment import GridWorld\n",
    "\n",
    "now = '30x40_randomAgent_fixedTarget_nomeans'\n",
    "\n",
    "scores = []\n",
    "averages = []\n",
    "episodes = []\n",
    "\n",
    "debug_mode = False\n",
    "show_graph_every = 1\n",
    "means = False\n",
    "resume = True\n",
    "\n",
    "\n",
    "env = GridWorld(show_graph_every, debug_mode, means)\n",
    "\n",
    "\n",
    "size = 1200\n",
    "\n",
    "\n",
    "\n",
    "class DQNSolver:\n",
    "\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        self.exploration_rate = EXPLORATION_MAX\n",
    "        self.action_space = action_space\n",
    "        self.memory = deque(maxlen=MEMORY_SIZE)\n",
    "        if resume:\n",
    "            self.model = keras.models.load_model('models/'+now+'.h5', custom_objects=None, compile=True)\n",
    "            print('Model loaded')\n",
    "            self.exploration_rate = EXPLORATION_MIN\n",
    "            self.model.compile(loss=\"mse\", optimizer=Adam(lr=LEARNING_RATE))\n",
    "            return\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(size, input_shape=(observation_space,), activation=\"relu\"))\n",
    "        self.model.add(Dense(size, activation=\"relu\"))\n",
    "        self.model.add(Dense(self.action_space, activation=\"linear\"))\n",
    "        self.model.compile(loss=\"mse\", optimizer=Adam(lr=LEARNING_RATE))\n",
    "        print('Model created')\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):        \n",
    "        if np.random.rand() < self.exploration_rate:\n",
    "            return random.randrange(self.action_space)\n",
    "        q_values = self.model.predict(state)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "    def save(self):\n",
    "        self.model.save('models/'+now+'.h5')   \n",
    "        print('model saved')\n",
    "    \n",
    "    def experience_replay(self, run):\n",
    "        if len(self.memory) < MIN_MEMORY_SIZE:\n",
    "            return\n",
    "        batch = random.sample(self.memory, BATCH_SIZE)\n",
    "        for state, action, reward, state_next, terminal in batch:\n",
    "            q_update = reward\n",
    "            if not terminal:\n",
    "                q_update = (reward + GAMMA * np.amax(self.model.predict(state_next)[0]))\n",
    "            q_values = self.model.predict(state)\n",
    "            q_values[0][action] = q_update\n",
    "            self.model.fit(state, q_values, verbose=0)                \n",
    "        self.exploration_rate *= EXPLORATION_DECAY\n",
    "        self.exploration_rate = max(EXPLORATION_MIN, self.exploration_rate)\n",
    "\n",
    "\n",
    "def cartpole():\n",
    "    env = GridWorld(show_graph_every, debug_mode, means)\n",
    "    #observation_space = env.observation_space.shape[0]\n",
    "    action_space = 6\n",
    "    observation_space = size\n",
    "    dqn_solver = DQNSolver(observation_space, action_space)\n",
    "    run = 0\n",
    "    while True:\n",
    "        run += 1\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, observation_space])\n",
    "        step = 0\n",
    "        while True:\n",
    "            step += 1\n",
    "            action = dqn_solver.act(state)\n",
    "            observe_past, reward, total_reward, state_next, terminal = env.step(action)\n",
    "            #reward = reward if not terminal else -reward\n",
    "            state_next = np.reshape(state_next, [1, observation_space])\n",
    "            dqn_solver.remember(state, action, reward, state_next, terminal)\n",
    "            state = state_next\n",
    "            if terminal:\n",
    "                print (\"Run: \" + str(run) + \", exploration: \" + str(dqn_solver.exploration_rate)[:4] + \", score: \" + str(total_reward)[:4] + ' step: '+ str(step))\n",
    "                PlotModel(total_reward, run)                \n",
    "                break\n",
    "            dqn_solver.experience_replay(run)\n",
    "        if run % 20 == 0:\n",
    "            dqn_solver.save()\n",
    "\n",
    "\n",
    "\n",
    "def cartpole_test():\n",
    "    #observation_space = env.observation_space.shape[0]\n",
    "    global show_graph_every\n",
    "    show_graph_every = 1\n",
    "    env = GridWorld(show_graph_every, debug_mode, means)\n",
    "    action_space = 5\n",
    "    observation_space = size\n",
    "    model = keras.models.load_model('models/'+now+'.h5', custom_objects=None, compile=True)\n",
    "    print('Model loaded')\n",
    "    run = 0\n",
    "    while True:\n",
    "        run += 1\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, observation_space])\n",
    "        step = 0\n",
    "        while True:\n",
    "            step += 1\n",
    "            action = np.argmax(model.predict(state)[0])\n",
    "            observe_past, reward, total_reward, state_next, terminal = env.step(action)\n",
    "            state_next = np.reshape(state_next, [1, observation_space])\n",
    "            state = state_next\n",
    "            if terminal:\n",
    "                print (\"Test: \" + str(run) + \", score: \" + str(total_reward)[:4] + ' step: '+ str(step))\n",
    "                break\n",
    "         \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "def PlotModel(score, episode_number):\n",
    "    scores.append(score)\n",
    "    averages.append(sum(scores[-50:]) / len(scores[-50:]))\n",
    "    episodes.append(episode_number)\n",
    "    pylab.plot(episodes, scores, 'b')\n",
    "    pylab.plot(episodes, averages, 'r')\n",
    "    pylab.ylabel('Score', fontsize=18)\n",
    "    pylab.xlabel('Games', fontsize=18)\n",
    "    file_name = \"breakout_model_{}\".format(now)\n",
    "    name = file_name + '.png'\n",
    "    try:\n",
    "        if not os.path.exists('training_images'): os.makedirs('training_images')\n",
    "        pylab.savefig('training_images/'+name)\n",
    "\n",
    "    except OSError as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    return    \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cartpole()\n",
    "    #cartpole_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
